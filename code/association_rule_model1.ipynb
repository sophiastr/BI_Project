{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ανάλυση Κανόνων Συσχετίσεων\n",
    "* Δηλώνω τις βιβλιοθήκες που θα χρησιμοποιήσω"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.frequent_patterns import apriori, association_rules"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* fact_table.txt -> το αρχείο έχει εξαχθεί από το data warehouse και αντιστοιχεί στον πίνακα fact Table όπως προέκυψε μετά τη διαδικασία ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('fact_table.txt', sep=\",\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Διώχνω όποιο βιβλίο έχει αγοραστεί λιγότερο από 100 φορές"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = data.groupby('Book').filter(lambda x : len(x)>100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Κρατάω μόνο όσους χρήστες έχουν αγοράσει πάνω από τρεις φορές"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = data_new.groupby('Reader').filter(lambda x : len(x)>3).copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Διατηρώ τους εναπομείναντες μοναδικούς τίτλους βιβλίων"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = pd.DataFrame (final['Book'].unique().copy(), columns = ['Book_Title'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Διατηρώ τους εναπομείναντες μοναδικούς χρήστες"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = final['Reader'].unique().copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Φτιάχνω ένα dictionary για τις ανάγκες του πίνακα. Δηλαδή ξεκινώντας από το 1 εως τον αριθμό του κάθε χρήστη και αντιστοιχώ user_id κατά αύξοντα αριθμό"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_dict = {}\n",
    "index = 0\n",
    "for i in users:\n",
    "    users_dict[i] = index\n",
    "    index = index + 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Φτιάχνω ένα data frame με γραμμές όσους και χρήστες και στήλες όσα και τα βιβλία. Γεμίζω το data frame με τιμές False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "association_df = pd.DataFrame(False, index=np.arange(3393), columns=titles.Book_Title)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Από το πίνακα final όπου περιέχει τα τελικά δεδομένα του Fact Table έτσι όπως εξήχθησαν από το Warehouse, ελέγχω τα βιβλία που διάβασε ο κάθε χρήστης. Με άλλα λόγια ελέγχω τον Fact Table και μόλις βρω ότι ο χρήστης έκανε κάποια κριτική για κάποιο βιβλίο πηγαίνω και σημειώνω στο association_df ότι ο συγκεκριμένος χρήστης όπου βρίσκεται στη γραμμή users_dict[row['Reader'] έχει διαβάσει το βιβλίο που βρίσκεται στη στήλη row['Book_Title']. Με αυτό το τρόπο έχω στο association_df την πληροφορία ποιος χρήστης διάβασε ποια βιβλία."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in final.iterrows():\n",
    "  association_df.at[users_dict[row['Reader']], row['Book']] = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Από προεπιλογή, το apriori επιστρέφει τους δείκτες των στηλών των στοιχείων, οι οποίοι μπορεί να είναι χρήσιμοι σε επόμενες λειτουργίες, όπως η εξόρυξη κανόνων συσχέτισης. Για καλύτερη αναγνωσιμότητα, μπορούμε να ορίσουμε use_colnames=True για να μετατρέψουμε αυτές τις ακέραιες τιμές στα αντίστοιχα ονόματα στοιχείων"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 146306 combinations | Sampling itemset size 2"
     ]
    }
   ],
   "source": [
    "df = apriori(association_df, min_support=0.01, use_colnames=True, verbose=1, max_len= None, low_memory=False )\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Επιλέγω τους κορυφαίους 10 συνδυασμούς"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ar = association_rules(df, metric = \"confidence\")\n",
    "final_results = df_ar.sort_values(by=['confidence'], ascending=False).iloc[:10][['antecedents', 'consequents', 'support', 'confidence', 'lift']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Τα τελικά αποτελέσματα με το book_id, απομένει ένα τελευταίο βήμα να εμφανίσω τα book_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>(36578, 36067, 130572, 36422)</td>\n",
       "      <td>(36120)</td>\n",
       "      <td>0.010315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.586957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>(116954, 117171, 116979)</td>\n",
       "      <td>(116977)</td>\n",
       "      <td>0.010315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.339623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>(82995, 123557, 82974)</td>\n",
       "      <td>(82757)</td>\n",
       "      <td>0.017683</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>26.073258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>(83596, 123557, 82974)</td>\n",
       "      <td>(82757)</td>\n",
       "      <td>0.013852</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>25.955566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>(82995, 83596, 123557)</td>\n",
       "      <td>(82757)</td>\n",
       "      <td>0.012084</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>25.876674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>(36578, 130572, 36422)</td>\n",
       "      <td>(36120)</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>23.972283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>(82995, 83596, 123557, 82974)</td>\n",
       "      <td>(82757)</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>25.845117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>(36578, 130572, 36277, 36422)</td>\n",
       "      <td>(36120)</td>\n",
       "      <td>0.010610</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>23.922444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>(36120, 36721, 36578)</td>\n",
       "      <td>(36277)</td>\n",
       "      <td>0.010315</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>24.078467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>(116954, 117171, 95630)</td>\n",
       "      <td>(116977)</td>\n",
       "      <td>0.010315</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>20.746855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       antecedents consequents   support  confidence  \\\n",
       "328  (36578, 36067, 130572, 36422)     (36120)  0.010315    1.000000   \n",
       "143       (116954, 117171, 116979)    (116977)  0.010315    1.000000   \n",
       "125         (82995, 123557, 82974)     (82757)  0.017683    0.983607   \n",
       "121         (83596, 123557, 82974)     (82757)  0.013852    0.979167   \n",
       "118         (82995, 83596, 123557)     (82757)  0.012084    0.976190   \n",
       "201         (36578, 130572, 36422)     (36120)  0.011494    0.975000   \n",
       "295  (82995, 83596, 123557, 82974)     (82757)  0.011494    0.975000   \n",
       "322  (36578, 130572, 36277, 36422)     (36120)  0.010610    0.972973   \n",
       "232          (36120, 36721, 36578)     (36277)  0.010315    0.972222   \n",
       "172        (116954, 117171, 95630)    (116977)  0.010315    0.972222   \n",
       "\n",
       "          lift  \n",
       "328  24.586957  \n",
       "143  21.339623  \n",
       "125  26.073258  \n",
       "121  25.955566  \n",
       "118  25.876674  \n",
       "201  23.972283  \n",
       "295  25.845117  \n",
       "322  23.922444  \n",
       "232  24.078467  \n",
       "172  20.746855  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Για να εμφανίσω τους τίτλους βιβλίων χρειάζομαι το πίνακα dimension book_title_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_dim = pd.read_csv('bookdimension.csv', sep=\"|\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Μετανομάζω και αφαιρώ κάποιες αχρείαστες στήλες"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_dim.columns = book_dim.columns.str.replace('book_id', 'Book_Title')\n",
    "book_dim.columns = book_dim.columns.str.replace('book_title', 'book_title_label')\n",
    "book_dim = book_dim.drop(['ISBN', 'year_of_publication'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Κάνω merge με τα βιβλία που χρησιμοποιήθηακν στον αλγόριθμο"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_results = pd.merge(book_dim, titles, on=['Book_Title'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Και εμφανίζω τα τελικά αποτελέσματα"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Seven Up (A Stephanie Plum Novel)', 'Three To Get Deadly : A Stephanie Plum Novel (A Stephanie Plum Novel)', 'Two for the Dough', 'Hot Six : A Stephanie Plum Novel (A Stephanie Plum Novel)'] ['Four To Score (A Stephanie Plum Novel)']\n",
      "----------->  support 0.01031535514294135 & confidence 1.0 \n",
      "['A Is for Alibi (Kinsey Millhone Mysteries (Paperback))', 'F Is for Fugitive (Kinsey Millhone Mysteries (Paperback))', 'C Is for Corpse (Kinsey Millhone Mysteries (Paperback))'] ['B Is for Burglar (Kinsey Millhone Mysteries (Paperback))']\n",
      "----------->  support 0.01031535514294135 & confidence 1.0 \n",
      "['Harry Potter and the Goblet of Fire (Book 4)', \"Harry Potter and the Sorcerer's Stone (Book 1)\", 'Harry Potter and the Prisoner of Azkaban (Book 3)'] ['Harry Potter and the Chamber of Secrets (Book 2)']\n",
      "----------->  support 0.01768346595932803 & confidence 0.9836065573770492 \n",
      "['Harry Potter and the Order of the Phoenix (Book 5)', \"Harry Potter and the Sorcerer's Stone (Book 1)\", 'Harry Potter and the Prisoner of Azkaban (Book 3)'] ['Harry Potter and the Chamber of Secrets (Book 2)']\n",
      "----------->  support 0.013852048334806955 & confidence 0.9791666666666667 \n",
      "['Harry Potter and the Goblet of Fire (Book 4)', 'Harry Potter and the Order of the Phoenix (Book 5)', \"Harry Potter and the Sorcerer's Stone (Book 1)\"] ['Harry Potter and the Chamber of Secrets (Book 2)']\n",
      "----------->  support 0.012083701738874153 & confidence 0.9761904761904763 \n",
      "['Seven Up (A Stephanie Plum Novel)', 'Two for the Dough', 'Hot Six : A Stephanie Plum Novel (A Stephanie Plum Novel)'] ['Four To Score (A Stephanie Plum Novel)']\n",
      "----------->  support 0.011494252873563218 & confidence 0.9750000000000001 \n",
      "['Harry Potter and the Goblet of Fire (Book 4)', 'Harry Potter and the Order of the Phoenix (Book 5)', \"Harry Potter and the Sorcerer's Stone (Book 1)\", 'Harry Potter and the Prisoner of Azkaban (Book 3)'] ['Harry Potter and the Chamber of Secrets (Book 2)']\n",
      "----------->  support 0.011494252873563218 & confidence 0.9750000000000001 \n",
      "['Seven Up (A Stephanie Plum Novel)', 'Two for the Dough', 'High Five (A Stephanie Plum Novel)', 'Hot Six : A Stephanie Plum Novel (A Stephanie Plum Novel)'] ['Four To Score (A Stephanie Plum Novel)']\n",
      "----------->  support 0.010610079575596816 & confidence 0.9729729729729728 \n",
      "['Four To Score (A Stephanie Plum Novel)', 'Hard Eight : A Stephanie Plum Novel (A Stephanie Plum Novel)', 'Seven Up (A Stephanie Plum Novel)'] ['High Five (A Stephanie Plum Novel)']\n",
      "----------->  support 0.01031535514294135 & confidence 0.9722222222222222 \n",
      "['A Is for Alibi (Kinsey Millhone Mysteries (Paperback))', 'F Is for Fugitive (Kinsey Millhone Mysteries (Paperback))', 'G Is for Gumshoe (Kinsey Millhone Mysteries (Paperback))'] ['B Is for Burglar (Kinsey Millhone Mysteries (Paperback))']\n",
      "----------->  support 0.01031535514294135 & confidence 0.9722222222222222 \n"
     ]
    }
   ],
   "source": [
    "for index, row in final_results.iterrows():\n",
    "  asc =[]\n",
    "  for r in row['antecedents']:\n",
    "    for ind, rr in book_results.iterrows():\n",
    "      if (r == rr['Book_Title']):\n",
    "        asc.append(rr['book_title_label'])\n",
    "        continue\n",
    "  con =[]\n",
    "  for r in row['consequents']:\n",
    "    for ind, rr in book_results.iterrows():\n",
    "      if (r == rr['Book_Title']):\n",
    "        con.append(rr['book_title_label'])\n",
    "        continue\n",
    "  print(asc, con)\n",
    "  print(\"----------->  \" + 'support ' + str(row['support']) + \" & confidence \"+ str(row['confidence'])+ ' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df5c7b8ffaedf80dec2b70b09605990d7e0e1b6bc745b497330e86cbe58a738e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
