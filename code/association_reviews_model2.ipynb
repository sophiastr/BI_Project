{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ανάλυση Κανόνων Συσχετίσεων\n",
    "* Σε αυτό το αρχείο θα αναζητήσω βιβλία που αγοράστηκαν συνδυαστικά και εκτιμήθηκαν\n",
    "* Έτσι, θα μπορέσουμε να προτείνουμε βιβλία σε άλλους χρήστες που πιθανόν να τους αρέσουν\n",
    "* Δηλώνω τις βιβλιοθήκες που θα χρησιμοποιήσω"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.frequent_patterns import apriori, association_rules"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* fact_table.txt -> το αρχείο έχει εξαχθεί από το data warehouse και αντιστοιχεί στον πίνακα fact Table όπως προέκυψε μετά τη διαδικασία ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('fact_table.txt', sep=\",\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Με δεδομένο ότι πλέον κάνω κανόνα συσχέτισης μόνο για τα \"ωραία βιβλία\" αφαιρώ βιβλία με κακές αξιολογήσεις και συγκεκριμένα με αξιολογήσεις μικρότερες του 6.\n",
    "* Με άλλα λόγια, πλέον δεν με ενδιαφέρει μόνο τα βιβλία που αγοράστηκαν συνδυαστηκάν αλλά τα βιβλία που αγοράστηκαν συνδυαστικά, απέκτησαν υψηλές αξιολογήσεις και είχαν απήχηση στους χρήστες"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_high = data[data['Rating_Score']>= 6].copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Διώχνω όποιο βιβλίο έχει αγοραστεί λιγότερο από 100 φορές"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = data_high.groupby('Book').filter(lambda x : len(x)>50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Κρατάω μόνο όσους χρήστες έχουν αγοράσει πάνω από τρεις φορές ώστε να έχει νόημα η πρόταση βιλίων "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = new.groupby('Reader').filter(lambda x : len(x)>3).copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Διατηρώ τους εναπομείναντες μοναδικούς τίτλους βιβλίων"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = pd.DataFrame (final['Book'].unique().copy(), columns = ['Book_Title'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Διατηρώ τους εναπομείναντες μοναδικούς χρήστες"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = final['Reader'].unique().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1114"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Φτιάχνω ένα dictionary για τις ανάγκες του πίνακα. Δηλαδή ξεκινώντας από το 1 εως τον αριθμό του κάθε χρήστη και αντιστοιχώ user_id κατά αύξοντα αριθμό"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1114"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_dict = {}\n",
    "index = 0\n",
    "for i in users:\n",
    "    users_dict[i] = index\n",
    "    index = index + 1\n",
    "len(users_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Φτιάχνω ένα data frame με γραμμές όσους και χρήστες και στήλες όσα και τα βιβλία. Γεμίζω το data frame με τιμές False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "association_df = pd.DataFrame(False, index=np.arange(1114), columns=titles.Book_Title)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Από το πίνακα final όπου περιέχει τα τελικά δεδομένα του Fact Table έτσι όπως εξήχθησαν από το Warehouse, ελέγχω τα βιβλία που διάβασε ο κάθε χρήστης. Με άλλα λόγια ελέγχω τον Fact Table και μόλις βρω ότι ο χρήστης έκανε κάποια κριτική για κάποιο βιβλίο πηγαίνω και σημειώνω στο association_df ότι ο συγκεκριμένος χρήστης όπου βρίσκεται στη γραμμή users_dict[row['Reader'] έχει διαβάσει το βιβλίο που βρίσκεται στη στήλη row['Book_Title']. Με αυτό το τρόπο έχω στο association_df την πληροφορία ποιος χρήστης διάβασε ποια βιβλία."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in final.iterrows():\n",
    "  association_df.at[users_dict[row['Reader']], row['Book']] = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Από προεπιλογή, το apriori επιστρέφει τους δείκτες των στηλών των στοιχείων, οι οποίοι μπορεί να είναι χρήσιμοι σε επόμενες λειτουργίες, όπως η εξόρυξη κανόνων συσχέτισης. Για καλύτερη αναγνωσιμότητα, μπορούμε να ορίσουμε use_colnames=True για να μετατρέψουμε αυτές τις ακέραιες τιμές στα αντίστοιχα ονόματα στοιχείων"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 264 combinations | Sampling itemset size 6543\n"
     ]
    }
   ],
   "source": [
    "df = apriori(association_df, min_support=0.005, use_colnames=True, verbose=1, max_len= None, low_memory=False )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Επιλέγω τους κορυφαίους 10 συνδυασμούς"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ar = association_rules(df, metric = \"confidence\")\n",
    "final_results = df_ar.sort_values(by=['confidence'], ascending=False).iloc[:5][['antecedents', 'consequents', 'support', 'confidence', 'lift']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Εμφανίζω τους κωδικούς βιβλίων των τελικών αποτελεσμάτων. Απομένει να αντικαταστήσω τους κωδικούς με τους τίτλους των βιβλίων"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>(36067, 36422, 36835)</td>\n",
       "      <td>(36120, 36277)</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>(36067, 130572, 36422)</td>\n",
       "      <td>(36120)</td>\n",
       "      <td>0.010772</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.906977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>(82995, 123557, 38215)</td>\n",
       "      <td>(82757)</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>(8585, 36067, 36422)</td>\n",
       "      <td>(36120)</td>\n",
       "      <td>0.005386</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.906977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>(82995, 123557, 38215)</td>\n",
       "      <td>(82974)</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.804598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                antecedents     consequents   support  confidence       lift\n",
       "233   (36067, 36422, 36835)  (36120, 36277)  0.006284         1.0  42.846154\n",
       "158  (36067, 130572, 36422)         (36120)  0.010772         1.0  25.906977\n",
       "90   (82995, 123557, 38215)         (82757)  0.006284         1.0  13.925000\n",
       "154    (8585, 36067, 36422)         (36120)  0.005386         1.0  25.906977\n",
       "87   (82995, 123557, 38215)         (82974)  0.006284         1.0  12.804598"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Για να εμφανίσω τους τίτλους βιβλίων χρειάζομαι το πίνακα dimension book_title_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_dim = pd.read_csv('bookdimension.csv', sep=\"|\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Μετανομάζω και αφαιρώ κάποιες αχρείαστες στήλες"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_dim.columns = book_dim.columns.str.replace('book_id', 'Book_Title')\n",
    "book_dim.columns = book_dim.columns.str.replace('book_title', 'book_title_label')\n",
    "book_dim = book_dim.drop(['ISBN', 'year_of_publication'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Κάνω merge με τα βιβλία που χρησιμοποιήθηακν στον αλγόριθμο"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_results = pd.merge(book_dim, titles, on=['Book_Title'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Και εμφανίζω τα τελικά αποτελέσματα"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Three To Get Deadly : A Stephanie Plum Novel (A Stephanie Plum Novel)', 'Hot Six : A Stephanie Plum Novel (A Stephanie Plum Novel)', 'One for the Money (A Stephanie Plum Novel)'] ['Four To Score (A Stephanie Plum Novel)', 'High Five (A Stephanie Plum Novel)']\n",
      "----------->  support 0.0062836624775583485 & confidence 1.0 \n",
      "['Three To Get Deadly : A Stephanie Plum Novel (A Stephanie Plum Novel)', 'Two for the Dough', 'Hot Six : A Stephanie Plum Novel (A Stephanie Plum Novel)'] ['Four To Score (A Stephanie Plum Novel)']\n",
      "----------->  support 0.010771992818671455 & confidence 1.0 \n",
      "['Harry Potter and the Goblet of Fire (Book 4)', \"Harry Potter and the Sorcerer's Stone (Book 1)\", 'The Catcher in the Rye'] ['Harry Potter and the Chamber of Secrets (Book 2)']\n",
      "----------->  support 0.0062836624775583485 & confidence 1.0 \n",
      "['One for the Money (Stephanie Plum Novels (Paperback))', 'Three To Get Deadly : A Stephanie Plum Novel (A Stephanie Plum Novel)', 'Hot Six : A Stephanie Plum Novel (A Stephanie Plum Novel)'] ['Four To Score (A Stephanie Plum Novel)']\n",
      "----------->  support 0.005385996409335727 & confidence 1.0 \n",
      "['Harry Potter and the Goblet of Fire (Book 4)', \"Harry Potter and the Sorcerer's Stone (Book 1)\", 'The Catcher in the Rye'] ['Harry Potter and the Prisoner of Azkaban (Book 3)']\n",
      "----------->  support 0.0062836624775583485 & confidence 1.0 \n"
     ]
    }
   ],
   "source": [
    "for index, row in final_results.iterrows():\n",
    "  asc =[]\n",
    "  for r in row['antecedents']:\n",
    "    for ind, rr in book_results.iterrows():\n",
    "      if (r == rr['Book_Title']):\n",
    "        asc.append(rr['book_title_label'])\n",
    "        continue\n",
    "  con =[]\n",
    "  for r in row['consequents']:\n",
    "    for ind, rr in book_results.iterrows():\n",
    "      if (r == rr['Book_Title']):\n",
    "        con.append(rr['book_title_label'])\n",
    "        continue\n",
    "  print(asc, con)\n",
    "  print(\"----------->  \" + 'support ' + str(row['support']) + \" & confidence \"+ str(row['confidence'])+ ' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df5c7b8ffaedf80dec2b70b09605990d7e0e1b6bc745b497330e86cbe58a738e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
